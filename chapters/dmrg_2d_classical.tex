\chapterprecishere{This chapter explains how to apply to ideas of the density matrix renormalization group to
two-dimensional classical lattices.

First, we explain the transfer-matrix formulation for
classical partition functions.

Then, we show how to renormalize the transfer matrix using DMRG.
This was first done by Nishino \cite{nishino1995density}.
To make notation easier and up-to-date with current approaches, we redefine the transfer matrix in terms of a tensor
network.

Then, we explain the
corner transfer matrix renormalization group (CTMRG) method. This method, first introduced by Nishino and
Okunishi \cite{nishino1996corner}, unifies ideas from Baxter \cite{baxter1968dimers,
baxter1978variational, baxter1982exactly_ctm} and White \cite{white1992density} to
significantly speed up the renormalization of the transfer matrix.}

\section{Statistical mechanics on classical lattices}
For a general introduction to statistical mechanics, we refer to \cite{tong2011lectures}.

The central quantity in equilibrium statistical mechanics is the partition
function $Z$, which, for a discrete system such as a lattice, is defined as
\begin{equation}
  Z = \sum_{s} \exp{(-\beta H(s))},
\end{equation}
where the sum is over all microstates $s$, $H$ is the energy function, and
$\beta = T^{-1}$ the inverse temperature.

The probability that the system is in a particular microstate
\begin{equation}
  p(s) = \frac{\exp (-\beta H(s)) }{Z}
\end{equation}
is also called the \emph{Boltzmann weight}.

At first glance, the partition function is a simple normalization factor.
But its importance stems from the fact that since it contains all statistical information about the system,
all thermodynamic quantities can be expressed as a function of $Z$.

The energy of the system is expressed as
\begin{equation}
  \langle E \rangle = \frac{\sum_{s} H(s) \exp{(-\beta H(s))}}{Z} = -\frac{\partial}{\partial \beta} \log Z,
\end{equation}
the entropy as
\begin{equation}
  S = - \sum_{s} p(s) \log p(s) = \frac{\partial}{\partial T}(T \log Z),
\end{equation}
and the free energy as
\begin{equation}
  F = \langle E \rangle - TS = T^2 \frac{\partial}{\partial T} \log Z - T \frac{\partial}{\partial T}(T \log Z) = -T \log Z.
\end{equation}





\section{Transfer matrices of lattice models}

Transfer matrices are used to re-express the partition function of classical
lattice systems, allowing them to be solved exactly or approximated.

We will introduce the transfer matrix in the context of the 1D classical
Ising model, first introduced and solved using the transfer matrix method by Ising
\cite{ising1925beitrag} in his PhD thesis.

\subsection{1D Ising model}
Consider the 1D ferromagnetic Ising model \cite{ising1925beitrag}, defined by the energy function
\begin{equation}\label{ising_energy_function}
  H(\sigma) = -J \sum_{\langle i j \rangle} \sigma_i \sigma_j - h \sum_{i} \sigma_i.
\end{equation}
Here, we sum over nearest neighbors $\langle i j \rangle$ and the spins
$\sigma_i$ take the values $\pm 1$. $J > 0$ is the spin coupling and $h > 0$ an external magnetic field.

Assume, for the moment, that the chain
consists of $N$ spins, and apply periodic boundary conditions.
The partition function of this system is given by
\begin{equation}
  Z_{N} = \sum_{\sigma_1, \dotsc, \sigma_N \in \{-1, 1\}} \exp (-\beta H(\sigma))
\end{equation}
Exploiting the local nature of the interaction between spins, we can write
\begin{equation}
  Z_{N} = \sum_{\sigma_1, \cdots, \sigma_N \in \{-1, 1\}} \prod_{\langle i, j \rangle} e^{K\sigma_i \sigma_j + \frac{H}{2}(\sigma_i + \sigma_j)}
\end{equation}
where we defined $K \equiv \beta J$ and $H \equiv \beta h$.

Now, we define the $2 \times 2$ matrix
\begin{equation}\label{eq:transfer_matrix_1d_ising}
  T_{\sigma \sigma'} = \exp(K \sigma \sigma' + \frac{H}{2}(\sigma + \sigma')).
\end{equation}
for which a possible choice of basis is
\begin{equation}\label{eq:basis_transfer_matrix_1d}
  \bigl( \ket{\uparrow} = 1, \ket{\downarrow} = -1 \bigr) =
  \bigl(
  \begin{bmatrix}
    1 \\
    0
  \end{bmatrix},
  \begin{bmatrix}
    0 \\
    1
  \end{bmatrix}
  \bigr).
\end{equation}

In terms of this matrix, $Z_N$ is written as
\begin{equation}\label{eq:partition_function_transfer_matrix_1d}
  Z_N = \sum_{\sigma_1, \cdots, \sigma_N} T_{\sigma_1 \sigma_2} \dotsm T_{\sigma_N \sigma_1} = \tr T^N.
\end{equation}
$T$ is called the transfer matrix. In the basis of \autoref{eq:basis_transfer_matrix_1d},
it is written as
\begin{equation}
  T = \begin{bmatrix}
    e^{K+H} & e^{-K} \\
    e^{-K} & e^{K-H}
  \end{bmatrix}.
\end{equation}

$T$ is, in fact, diagonalizable. So, we can write $T^N = P D^N
P^{-1}$, where $P$ consists of the eigenvectors of $T$, and $D$ has the corresponding eigenvalues on the diagonal. By the cyclic property of the
trace, we have
\begin{equation}
  Z_N = \lambda_{+}^{N} + \lambda_{-}^{N},
\end{equation}
where
\begin{equation}
  \lambda_{\pm} = e^{K} \left[ \cosh(H) \pm \sqrt{\sinh^2(H) + e^{-4K}} \right]
\end{equation}
Thus, we have reduced the problem of finding the partition function to an
eigenvalue problem.

In the thermodynamic limit $N \to \infty$
\begin{equation}
  Z = \lim_{N \to \infty} \lambda_{+}^{N}
\end{equation}
where $\lambda_+$ is the non-degenerate largest eigenvalue (in absolute value) of $T$.
Thermodynamic quantities like the free energy per site
\begin{equation}
  \frac{F}{N} = -T \log \lambda_{+}
\end{equation}
and the magnetization per site
\begin{equation}
   M = \frac{\sum_{i}^{N} \langle \sigma_i \rangle}{N} = - \frac{1}{N}\frac{\partial F}{\partial h}
\end{equation}
can now readily be calculated.

\subsubsection{Fixed boundary conditions}\label{sec:fixed_boundary_conditions}
We may also apply fixed boundary conditions. The partition function is then written as
\begin{equation}
  Z_N = \bra{\sigma'}T^N\ket{\sigma},
\end{equation}
where $\ket{\sigma}$ and $\ket{\sigma'}$ are the right and left boundary spins.

In the large-$N$ limit, $T^N$ tends towards the projector onto the eigenspace spanned by
the eigenvector belonging to the largest eigenvalue
\begin{equation}\label{eq:largest_eigenvector}
  \ket{\lambda_+} = \lim_{N \to \infty} \frac{T^N \ket{\sigma}}{\left\lVert T^N \ket{\sigma} \right\rVert}.
\end{equation}

\autoref{eq:largest_eigenvector} is true for any $\ket{\sigma}$ that is not orthogonal to $\ket{\lambda_+}$.

The physical significance of the normalized lowest-lying eigenvector $\ket{\lambda_1}$ is
that
$\braket{\lambda_1 | \uparrow}$ and
$\braket{\lambda_1 | \downarrow}$ represent the Boltzmann weight of $\ket{\uparrow}$ and
$\ket{\downarrow}$ at the boundary of a half-infinite chain.
\todo[inline]{Maybe picture of above claim?}

\subsection{2D Ising model}
\todo[inline]{Talk about exact solution (Onsager). Why is it important? Maybe
star-triangle relation (Baxter). Not all IRF models solvable.}

Next, we treat the two-dimensional, square-lattice Ising model. In two
dimensions, the energy function is still written as in
\autoref{ising_energy_function}, but now every lattice site has four neighbors.

Let $N$ be the number of columns and $l$ be the number of rows of the lattice, and assume
$l \gg N$. In the vertical direction, we apply periodic boundary conditions, as in the
one-dimensional case. In the horizontal direction, we keep an open boundary. We refer to
$N$ as the system size. \todo[inline]{Picture?}

Similarly as in the 1D case, the partition function can be written as
\begin{equation}
  Z_N = \sum_{\bm{\sigma}} \prod_{\langle i, j, k, l \rangle} W(\sigma_i, \sigma_j, \sigma_k, \sigma_l)
\end{equation}
where the product runs over all groups of four spins sharing the same face. The Boltzmann weight of such a face is given by
\begin{equation}\label{eq:boltzmann_weight_face_ising_model}
  W(\sigma_i, \sigma_j, \sigma_k, \sigma_l) = \exp \left\{ \frac{K}{2} (\sigma_i \sigma_j + \sigma_j \sigma_k + \sigma_k \sigma_l + \sigma_l \sigma_i) \right\}
\end{equation}

We can express the Boltzmann weight of a configuration of the whole lattice as
a product of the Boltzmann weights of the rows
\begin{equation}
  Z_N = \sum_{\bm{\sigma}} \prod_{r = 1}^{l} W(\sigma_{1}^{r}, \sigma_{2}^{r}, \sigma_{1}^{r+1}, \sigma_{2}^{r+1}) \dots W(\sigma_{N-1}^{r}, \sigma_{N}^{r}, \sigma_{N-1}^{r+1}, \sigma_{N}^{r+1})
\end{equation}
where $\sigma_{i}^{r}$ denotes the value of the $i$th spin of row $r$.

Now, we can generalize the definition of the transfer matrix to two dimensions, by
defining it as the Boltzmann weight of an entire row
\begin{equation}\label{eq:row_to_row_transfer_matrix}
  T_{N}(\bm{\sigma}, \bm{\sigma'}) = W(\sigma_1, \sigma_2, \sigma_1', \sigma_2') \dots W(\sigma_{N-1}, \sigma_N, \sigma_{N-1}', \sigma_{N}')
\end{equation}
If we take the spin configurations of an entire row as basis vectors, $T_N$ can be written
as a matrix of dimensions $2^N \times 2^N$.

Similarly as in the one-dimensional case, the partition function now becomes
\begin{equation}\label{eq:z_n_times_infty}
  Z_N = \sum_{\bm{\sigma}} \prod_{r = 1}^{l} T_{N}(\bm{\sigma}^r, \bm{\sigma}^{r+1}) = \tr T_{N}^l
\end{equation}

In the limit of an $N \times \infty$ cylinder, the partition function is once again
determined by the largest eigenvalue\footnote{As in the 1D case, $T$ is symmetric, so it
is orthogonally diagonalizable.}.
\begin{equation}\label{largest_eigenvalue_transfer_matrix}
  Z_N = \lim_{l \to \infty} T_{N}^{l} = \lim_{l \to \infty} (\lambda_0)_{N}^{l}
\end{equation}

The partition function in the thermodynamic limit is given by
\begin{equation}
  Z = \lim_{N \to \infty} Z_N
\end{equation}

\section{Partition function of the 2D Ising model as a tensor network}
In calculating the partition function of 1D and 2D lattices, matrices of Boltzmann weights
like $W$ and $T$ play a crucial role. We have formulated them in a way that is valid for
any interaction-round-a-face (IRF) model, defined by
\begin{equation}
  H \propto \sum_{\langle i, j, k, l \rangle} W(\sigma_i, \sigma_j, \sigma_k,
  \sigma_l),
\end{equation}
where the summation is over all spins sharing a face. $W$ can contain 4-spin,
3-spin, 2-spin and 1-spin interaction terms. The Ising model is a special case of the IRF
model, with $W$ given by \autoref{eq:boltzmann_weight_face_ising_model}.

We will now express the partition function of the 2D Ising model as a tensor network. The
transfer matrix $T$ is redefined in the process. This allows us to visualize the equations
in a way that is consistent with the many other tensor network algorithms under research
today. For an introduction to tensor network notation, see
\autoref{chapter:introduction_to_tensor_networks}.

\subsection{Tensor network of the partition function of a system of four spins}

We define
\begin{equation}
  Q(\sigma_i, \sigma_j) = \exp(K \sigma_i \sigma_j)
\end{equation}
as the Boltzmann weight of the bond between $\sigma_i$ and $\sigma_j$. It is the
same as the 1D transfer matrix in \autoref{eq:transfer_matrix_1d_ising}.

The Boltzmann weight of a face $W$ decomposes into a product of Boltzmann weights of
bonds
\begin{equation}
  W(\sigma_i, \sigma_j, \sigma_k, \sigma_l) =
  Q(\sigma_i, \sigma_j)Q(\sigma_j, \sigma_l)Q(\sigma_l, \sigma_k)Q(\sigma_k, \sigma_i).
\end{equation}

It is now easy to see that the partition function is equal to the contracted tensor
network in \autoref{fig:tensor_network_4_sites}:
\begin{equation}\label{eq:tensor_network_4_sites}
  \begin{split}
    Z_{2 \times 2} & =
    \sum_{\sigma_1, \sigma_2, \sigma_3, \sigma_4} \sum_{a, b, c, d}
    \delta_{\sigma_1, a} Q(a, b) \delta_{\sigma_2, b} Q(b, c)
    \delta_{\sigma_3, c} Q(c, d) \delta_{\sigma_4, d} Q(d, a) \\
    & =
    \sum_{\sigma_1, \sigma_2, \sigma_3, \sigma_4} W(\sigma_1, \sigma_2, \sigma_3, \sigma_4).
  \end{split}
\end{equation}
where the Kronecker delta is defined as usual:
\begin{equation}
  \delta_{i j} =
  \begin{cases}
    1 & \text{if } i = j \\
    0 & \text{if } i \neq j.
  \end{cases}
\end{equation}

\begin{figure}
  \input{images/tensor_network_4_sites.tikz}
  \caption{A tensor network representation of the partition function of the Ising model on
  a $2 \times 2$ lattice. See \autoref{eq:tensor_network_4_sites}.}
  \label{fig:tensor_network_4_sites}
\end{figure}


\subsection{Thermodynamic limit}
\begin{figure}
  \input{images/q_to_p.tikz}
  \caption{Graphical form of \autoref{eq:q_to_p}.}
  \label{fig:q_to_p}
\end{figure}

\begin{figure}
  \input{images/a_tensor.tikz}
  \caption{Graphical form of \autoref{eq:a_tensor}.}
  \label{fig:a_tensor}
\end{figure}

We define the matrix $P$ by
\begin{equation}\label{eq:q_to_p}
  P^2 = Q.
\end{equation}
as in \autoref{fig:q_to_p}. This allows us to write the partition function of an arbitrary
$N \times l$ square lattice as a tensor network of a single recurrent tensor $a_{i j k
l}$, given by
\begin{equation}\label{eq:a_tensor}
  a_{i j k l} = \sum_{a, b, c, d} \delta_{a b c d} P_{i a} P_{j b} P_{k c} P_{l d},
\end{equation}
where the generalization of the Kronecker delta is defined as
\begin{equation}
  \delta_{i_1 \dots i_n} =
  \begin{cases}
    1 & \text{if } i_1 = \ldots = i_n \\
    0 & \text{otherwise.}
  \end{cases}
\end{equation}

See \autoref{fig:a_tensor} and \autoref{fig:2d_ising_as_tensor_network}. At the edges and
corners, we define suitable tensors of rank 3 and 2, which we will also denote by $a$:
\begin{align*}
  a_{i j k} &= \sum_{a b c} \delta_{a b c} P_{i a} P_{j b} P_{k c}, \\
  a_{i j} &= \sum_{a b} \delta_{a b} P_{i a} P_{j b}.
\end{align*}

The challenge is to approximate this tensor network in the thermodynamic limit.

\begin{figure}
  \input{images/2d_ising.tikz}
  \caption{$Z_{N \times l}$ can be written as a contracted tensor network of $N \times l$
  copies of the tensor $a$.}
  \label{fig:2d_ising_as_tensor_network}
\end{figure}

\subsection{The transfer matrix as a tensor network}
\todo[inline]{Say something about reshaping legs. It is implicit now.}

With our newfound representation of the partition function as a tensor network, we can
redefine the row-to-row transfer matrix from
\autoref{eq:row_to_row_transfer_matrix} as the tensor network expressed in
\autoref{fig:transfer_matrix_as_tensor_network}. For all $l$, it is still true that
\begin{equation}
  Z_{N \times l} = \tr T_{N}^{l} = \sum_{i = 1}^{2^N} \lambda_{i}^{l},
\end{equation}
so the eigenvalues must be the same. That means that the new definition of the transfer
matrix is related to the old one by a basis transformation
\begin{equation}
  T_{\text{new}} = P T_{\text{old}} P^{T}.
\end{equation}

\begin{figure}
  \input{images/transfer_matrix.tikz}
  \caption{The definition of $T_N$ as a network of $N$ copies of the tensor $a$.}
  \label{fig:transfer_matrix_as_tensor_network}
\end{figure}

\section{Transfer matrix renormalization group}\label{sec:tmrg}
There is a deep connection between quantum mechanical lattice systems in $d$ dimensions
and classical lattice systems in $d + 1$ dimensions. Via the imaginary time path integral
formulation, the partition function of a one-dimensional quantum system can be written as
the partition function of an effective two-dimensional classical system. The ground state
of the quantum system corresponds to the largest eigenvector of the transfer matrix of the
classical system.

For more on the quantum-classical correspondence, see
\autoref{chapter:correspondence_quantum_classical}.

\subsection{The infinite system algorithm for the transfer matrix}
Nishino \cite{nishino1995density, nishino1996corner} was the first to apply density matrix
renormalization group methods in the context of two-dimensional classical
lattices.

Analogous to the infinite system DMRG algorithm for approximating the Hamiltonian of
quantum spin chains, our goal is to
approximate the transfer matrix in the thermodynamic limit as well as possible within a
restriced number of basis states $m$. We will do this by adding a single site at a time,
and truncating the dimension from $2m$ to $m$ at each iteration.

For simplicity, we assume that, at the start of the algorithm, the transfer matrix already
has dimension $m$. We call this transfer matrix $P_N$. A good choice of initial
transfer matrix is obtained by contracting a couple of $a$-tensors, until dimension $m$ is
reached. See \autoref{fig:tmrg_initial_half_row_transfer_matrix}.

To specify fixed instead of open boundary conditions, we may use as boundary tensor a
slightly modified version of the three-legged version of $a$, namely
\begin{equation}
  a_{i j k}^{\sigma} = \sum_{a b c} \delta_{\sigma a b c} P_{i a}P_{j b}P_{k c},
\end{equation}
that represents an edge site with spin fixed at $\sigma$.

We enlarge the system with one site by contracting with an additional $a$-tensor,
obtaining $P_{N + 1}$. See the first network in
\autoref{fig:tmrg_add_site_and_renormalize}.

In order to find the best projection from $2m$ basis states back to $m$, we embed the
system in an environment that is the mirror image of the system we presently have. We call
this matrix $T_{2N + 2}$. It represents the transfer matrix of $2N + 2$ sites. We find the
largest eigenvalue and corresponding eigenvector, as shown in
\autoref{fig:tmrg_eigenvalue_equation}.

The equivalent of the \textit{reduced density matrix of a
block} in the classical case is:
\begin{equation}\label{eq:reduced_density_matrix_classical_case}
  \rho_{N + 1} = \sum_{\sigma_B} \braket{\sigma_B | \lambda_0}\braket{\lambda_0 |
  \sigma_B},
\end{equation}
where we have summed over all the degrees of freedom of one of the half-row transfer
matrices $P_{N+1}$. See the first step of \autoref{fig:tmrg_reduced_density_matrix}.

The optimal renormalization
\begin{equation}
  \widetilde{P}_{N+1} = O P_{N + 1} O^{\dagger}
\end{equation}
is obtained by diagonalizing $\rho_{N + 1}$ and keeping the eigenvectors corresponding
to the $m$ largest eigenvalues. See the second step of \autoref{fig:tmrg_reduced_density_matrix}.

With this blocking procedure, we can successively find
\begin{equation}
    P_{N + 1} \rightarrow P_{N + 2} \rightarrow \dots,
\end{equation}
until we have reached some termination condition.\footnote{The termination condition for the infinite-system algorithm
is discussed in \autoref{sec:convergence_criteria}.}

\begin{figure}
  \input{images/tmrg_initial_half_row_transfer_matrix.tikz}
  \caption{A good starting point for the half-row transfer $P_N$ is obtained by
  contracting a couple of $a$-tensors, until $P_N$ reaches dimension $m$.}
  \label{fig:tmrg_initial_half_row_transfer_matrix}
\end{figure}

\begin{figure}
  \input{images/tmrg_add_site_and_renormalize.tikz}
  \caption{In the first step, $P_{N + 1}$ is obtained by contracting the current half-row
  transfer matrix $P_N$ with an additional $a$-tensor.
  In the second step, $P_{N + 1}$ is truncated back to an $m$-dimensional matrix, with the
  optimal low-rank approximation given by keeping the basis states corresponding to the
  $m$ largest eigenvalues of the density matrix. See
  \autoref{fig:tmrg_reduced_density_matrix}. }
  \label{fig:tmrg_add_site_and_renormalize}
\end{figure}

\begin{figure}
  \input{images/tmrg_eigenvalue_equation.tikz}
  \caption{Equation for the lowest-lying eigenvector of the row-to-row transfer matrix $T_{2N +
  2}$.}
  \label{fig:tmrg_eigenvalue_equation}
\end{figure}

\begin{figure}
  \input{images/tmrg_reduced_density_matrix.tikz}
  \caption{Graphical form of
  \autoref{eq:reduced_density_matrix_classical_case}.
  In the second step, $\rho_{N + 1}$ is diagonalized and only the eigenvectors
  corresponding to the $m$ largest eigenvalues are kept.
  }
  \label{fig:tmrg_reduced_density_matrix}
\end{figure}

\subsection{Physical interpretation of the reduced density matrix}
Generalizing the remarks from \autoref{sec:fixed_boundary_conditions} to the
two-dimensional case, we see that the normalized lowest-lying eigenvector of the transfer
matrix $T_N$ contains the Boltzmann weights of spin configurations on the boundary of a
half-infinite $N \times \infty$ lattice.

Therefore, the classical equivalent of the quantum mechanical reduced density matrix,
given by \autoref{eq:reduced_density_matrix_classical_case}, and by the first network in
\autoref{fig:tmrg_reduced_density_matrix}, represents the Boltzmann weights of
configurations along a cut in an $N \times \infty$ lattice.

Nishino and Okunishi \cite{nishino1996corner}, drawing on ideas from Baxter, realized the
Boltzmann weights of configurations along this cut could be obtained by employing
\textit{corner transfer matrices}, making it unneccessary to solve the eigenvalue problem
in \autoref{fig:tmrg_eigenvalue_equation}. Their method, called the Corner Transfer Matrix
Renormalization Group method, consumes far less resources while maintaining precision. For
this reason, it is the method of choice for most of the simulations in this thesis.


\section{Corner transfer matrix renormalization group}
\subsection{Corner transfer matrices}

The concept of corner transfer matrices for 2D lattices was first introduced by
Baxter \cite{baxter1968dimers, baxter1978variational, baxter1982exactly_ctm}.
Whereas the row-to-row transfer matrix \autoref{eq:row_to_row_transfer_matrix}
corresponds to adding a row to the lattice, the corner transfer matrix adds
a quadrant of spins. It was originally defined by Baxter as

\begin{equation}\label{eq:corner_transfer_matrix}
  A_{\bm{\sigma}, \bm{\sigma'}} =
  \begin{cases}
    \sum \prod_{\langle i, j, k, l \rangle} W(\sigma_i, \sigma_j, \sigma_k, \sigma_l) & \text{if } \sigma_{1} = \sigma_{1}' \\
    0 & \text{if } \sigma_{1} \neq \sigma_{1}'.
  \end{cases}
\end{equation}
Here, the product runs over groups of four spins that share the same face, and
the sum is over all spins in the interior of the quadrant.

In a symmetric and isotropic model such as the Ising model, we have
\begin{equation}
  W(a, b, c, d) = W(b, a, d, c) = W(c, a, d, b) = W(d, c, b, a)
\end{equation}
and the partition of an $N \times N$ lattice is expressed as
\begin{equation}\label{eq:z_n_times_n}
  Z_{N \times N} = \tr A^4.
\end{equation}

In the thermodynamic limit, this partition function is equal to
the partition function of an $N \times \infty$ lattice, given by
\autoref{eq:z_n_times_infty}.

The matrix in \autoref{eq:reduced_density_matrix_classical_case}, containing the Boltzmann
weights of spins along a cut down the middle of an $N \times \infty$ system, is
\textit{approximated} by
\begin{equation}
  \rho = A^4.
\end{equation}
The difference is that $A^4$ represents a square system of size $N \times N$ with a
cut, instead of an $N \times \infty$ strip with a cut. In the thermodynamic limit, both
systems become the same. In the corner transfer matrix renormalization group method, $A^4$
is used to find the optimal projector onto $m$ basis states.

\subsection{Corner transfer matrix as a tensor network}
Similarly to how we redefined the row-to-row transfer matrix
(\autoref{eq:row_to_row_transfer_matrix}) as the tensor network in
\autoref{fig:transfer_matrix_as_tensor_network}, we can redefine the corner transfer
matrix (\autoref{eq:corner_transfer_matrix}) as the tensor network in
\autoref{fig:corner_transfer_matrix_as_tensor_network}. Again, the new and old definitions
of $A$ are related by a basis tranformation
\begin{equation}
  A_{\text{new}} = P A_{\text{old}} P^T.
\end{equation}

The partition function, as in \autoref{eq:z_n_times_n}, is given by the tensor network in
\autoref{fig:partition_function_tensor_network}.

\begin{figure}
  \input{images/corner_transfer_matrix_as_tensor_network.tikz}
  \caption{Corner transfer matrix expressed as a contraction of $a$-tensors.}
  \label{fig:corner_transfer_matrix_as_tensor_network}
\end{figure}

\begin{figure}
  \input{images/partition_function_tensor_network.tikz}
  \caption{Tensor network approximation to $Z_{N \times N}$ in the CTMRG method.}
  \label{fig:partition_function_tensor_network}
\end{figure}

\subsection{Corner transfer matrix renormalization group method}
The algorithm proceeds very much like the transfer matrix renormalization group method. In addition to renormalizing the half-row transfer matrix $P$, we also renormalize the
corner transfer matrix $A$ at each step, using the projector obtained from diagonalizing
$A^4$.

\todo[inline]{Compare complexities of both algorithms?}

We first initialize $P_N$ and $A_N$, imposing boundary conditions as we see fit.

We then obtain the unrenormalized $A_{N+1}$ by adding a layer of spins to the quadrant
represented by $A_N$. This is done by contracting with two half-row transfer matrices
$P_N$ and a single $a$-tensor, as shown in the first step of
\autoref{fig:ctmrg_add_site_and_renormalize}. We obtain the unnormalized $P_{N+1}$ as
before, as shown in the first step of \autoref{fig:tmrg_add_site_and_renormalize}.

To find the optimal projector from $2m$ to $m$ basis states, we can directly diagonalize
$A_{N + 1}^4$, or, equivalently, $A_{N + 1}$. As always, we keep the basis states
corresponding to the $m$ largest eigenvectors. This is shown in
\autoref{fig:ctmrg_reduced_density_matrix}. We use the projector to obtain the
renormalized versions of $A_{N + 1}$ and $T_{N + 1}$
\begin{align}
    \widetilde{A}_{N + 1} &= OA_{N + 1}O^{\dagger}, \\
    \widetilde{T}_{N + 1} &= OT_{N + 1}O^{\dagger}.
\end{align}
shown in the second steps of \autoref{fig:ctmrg_add_site_and_renormalize} and
\autoref{fig:tmrg_add_site_and_renormalize}.

We repeat the above procedure to successively obtain
\begin{align}
  A_{N + 1} & \rightarrow A_{N + 2} \rightarrow \dots, \\
  T_{N + 1} & \rightarrow T_{N + 2} \rightarrow \dots
\end{align}
until a convergence criterion is reached.

\begin{figure}
  \input{images/ctmrg_add_site_and_renormalize.tikz}
  \caption{In the first step, the unrenormalized $A_{N+1}$ is obtained by contracting with
  two copies of $P_N$ and a single $a$-tensor. This corresponds to adding a layer of spins
  to the quadrant, thus enlarging it from $N \times N$ to $N + 1 \times N + 1$. In the
  second step, $A_{N + 1}$ is renormalized with the projector obtained from diagonalizing
  $A_{N+1}^4$ and keeping the basis states corresponding to the $m$ largest eigenvalues.  }
  \label{fig:ctmrg_add_site_and_renormalize}
\end{figure}

\begin{figure}
  \input{images/ctmrg_reduced_density_matrix.tikz}
  \caption{The matrix $A_{N+1}^4$ is approximately equal to $\rho_{N+1}$ in
  \autoref{eq:reduced_density_matrix_classical_case}. Compare the graphical forms of this
  network and the one shown in \autoref{fig:tmrg_reduced_density_matrix}. We obtain the
  optimal projector by diagonalizing $A_{N + 1}^4$, or equivalently $A_{N+1}$.}
  \label{fig:ctmrg_reduced_density_matrix}
\end{figure}



\section{Calculation of observable quantities}
\subsection{Free energy per site}
Baxter \cite{baxter1978variational, baxter1982exactly_ctm} showed that the partition function per site
\begin{equation}
  \kappa = Z^{1/N^2}
\end{equation}
is, within the corner transfer matrix renormalization group method, written as
\begin{equation}\label{eq:partition_function_per_site_variational_approximation}
  \kappa = \frac{r_1 r_4}{r_2 r_3},
\end{equation}
with $r_2$, $r_3$ and $r_4$ as in \autoref{fig:partition_function_per_site_tensor_networks} and $r_1 = Z_{N \times N}$
as in \autoref{fig:partition_function_tensor_network}. The free energy per site is then simply
\begin{equation}
  \frac{F}{N^2} = -T \log \kappa.
\end{equation}

\begin{figure}
  \begin{subfigure}{.33\linewidth}
    \input{images/ctmrg_two_columns.tikz}
    % \caption{A subfigure}\label{fig:1a}
  \end{subfigure}%
  \begin{subfigure}{.33\linewidth}
    \input{images/ctmrg_two_rows.tikz}
    % \caption{Another subfigure}\label{fig:1b}
  \end{subfigure}
  \begin{subfigure}{.33\linewidth}
    \input{images/ctmrg_four_corners.tikz}
    % \caption{Another subfigure}\label{fig:1b}
  \end{subfigure}
  \caption{From left to right:
  $r_2$, $r_3$ and $r_4$ as in
  \autoref{eq:partition_function_per_site_variational_approximation}.}
  \label{fig:partition_function_per_site_tensor_networks}
\end{figure}


\subsection{Magnetization per site}\label{sec:magnetization_per_site}
The magnetization per site may be calculated as
\begin{equation}
  M = T \frac{\partial (\log \kappa)}{\partial h},
\end{equation}
but this involves a numerical derivative and a numerical limit $h \to 0$ in the case of the spontaneous magnetization.
A more practical method, that is employed in this thesis, is to use the magnetization of the central spin
\begin{equation}
  \langle \sigma_0 \rangle = \frac{\tr A_{+}^4 - \tr A_{-}^4}{\tr A^4}
\end{equation}
as a proxy quantity to the magnetization per site.
Here, $A_{\pm}$ is the corner transfer matrix with the central spin fixed to $\pm$.

$\tr A_{+}^4 - \tr A_{-}^4$ is written as the tensor network in \autoref{fig:magnetization_central_spin_tensor_network},
with the tensor $b_{i j k l}$ defined as
\begin{equation}\label{eq:b_tensor}
  b_{i j k l} = \sum_{\sigma \in \{ -1, 1 \} } \sigma \delta_{\sigma i j k l}.
\end{equation}

All numerical results in this thesis involving the magnetization per site are actually obtained by calculating $\langle
\sigma_0 \rangle$, which shall be referred to simply as $M$ from now on.

\begin{figure}
  \input{images/magnetization_central_spin_tensor_network.tikz}
  \caption{Unnormalized expectation value of central spin, with the tensor $b_{i j k l}$ defined in \autoref{eq:b_tensor}.}
  \label{fig:magnetization_central_spin_tensor_network}
\end{figure}

\subsection{Analogy to entanglement entropy for classical systems}
The key point of the corner transfer matrix renormalization group method \cite{nishino1997corner, nishino1996corner} is
that it unifies White's density matrix renormalization group method \cite{white1992density} with Baxter's corner
transfer matrix approach \cite{baxter1968dimers, baxter1978variational}, through the identification (in the isotropic
case)
\begin{equation}\label{eq:correspondence_density_matrix_ctm}
  \rho_{\text{half-chain}} = A^4.
\end{equation}

This allows one to define a 2D classical analogue to the half-chain entanglement entropy of a 1D quantum system
\begin{equation}\label{eq:classical_entropy}
  S_{\text{classical}} = - \tr A^4 \log A^4 = - \sum_{\alpha=1}^{m} \nu_{\alpha}^4 \log \nu_{\alpha}^4,
\end{equation}
where $\nu_{\alpha}$ are the eigenvalues of the corner transfer matrix $A$.
In the CTMRG algorithm, $A$ is kept in diagonal form, making $S_{\text{classical}}$ trivial to compute.

In \cite{huang2017holographic}, numerical evidence is given for the validity of \autoref{eq:classical_entropy} for a
wide range of models, and the concept is generalized to higher dimensions. For an overview of applying corner transfer
matrices in higher dimensions and to quantum systems, see \cite{orus2012exploring}.

\section{Spectrum of the corner transfer matrix}\label{sec:spectrum_of_ctm}

\subsection{Analytical results for the Ising model}
In what follows, we present results established in \cite{peschel2009reduced, peschel1999density}.

For the off-critical Ising model on a square lattice, we have \cite{davies1988corner}
\begin{equation}\label{eq:rho_exact_expression_off_critical}
  \hat{\rho} = \hat{A}^4 = \exp(-\hat{H}_{\text{CTM}}),
\end{equation}
where
\begin{equation}
  \hat{H}_{\text{CTM}} = \sum_{l = 0}^{\infty} \epsilon_l(T) c^{\dagger}_l c_l,
\end{equation}
with $c_l$ and $c^{\dagger}_l$ fermionic annihilation and creation operators and
\begin{equation}
  \epsilon_l =
  \begin{cases}
    (2l + 1)\epsilon(T) & \text{if } T > T_c, \\
    2l\epsilon(T) & \text{if } T < T_c.
  \end{cases}
\end{equation}
with $\epsilon(T)$ a model-specific factor that only depends on temperature.

In other words, the reduced density matrix (or equivalently, the corner transfer matrix $A$) can be written as a
density matrix of an effective free fermionic Hamiltonian with equally spaced excitations.

What does this mean for the spectrum of $A$?
If we assume a free boundary, we have to distinguish between the ordered and disordered phase.

In the disordered phase, we have $\epsilon_l = (2l + 1)\epsilon(T)$.
The ground state, $E = 0$, corresponds to the vacuum state of the effective system described by $H_{\text{CTM}}$.
The single-fermion excitations give $\epsilon, 3\epsilon, 5\epsilon,
\dots$, while two-fermion excitations give $4\epsilon$ ($c^{\dagger}_0 c^{\dagger}_1 \ket{0}$),
$6\epsilon$ ($c^{\dagger}_0 c^{\dagger}_2 \ket{0}$) and $8\epsilon$ ($c^{\dagger}_0 c^{\dagger}_3 \ket{0}$ \emph{or}
$c^{\dagger}_1 c^{\dagger}_2 \ket{0}$).
So the first degeneracy appears at $8\epsilon$.
$9\epsilon$ is also degenerate:
it can be constructed with a single-fermion excitation ($ c^{\dagger}_4 \ket{0} $) and a three-fermion
excitation ($ c^{\dagger}_2 c^{\dagger}_1 c^{\dagger}_0 \ket{0} $).

The numerical results from the CTMRG algorithm exactly confirm this picture.
See the $T = 2.6$ line in the left panel of \autoref{fig:spectrum_ctm}. The gap after the first two eigenvalues is due
to the absence of the level $2\epsilon$. The $\epsilon_l$ are linear and the degeneracies are correct.

In the ordered phase, we have a two-fold degeneracy for every state due to symmetry and
ground state energy $E = 0$.
After that, the only available levels are $2\epsilon, 4\epsilon, 6\epsilon,
\dots$.
The degeneracy of the $n$th energy level is given by $2p(n)$, twice the number of partitions of $n$ into distinct integers
\cite{okunishi1999universal}, with the factor of two coming from symmetry.

To illustrate:
$c^{\dagger}_1 c^{\dagger}_2 \ket{0}$ and $c^{\dagger}_3 \ket{0}$ both have $E = 6\epsilon$,
the third energy level (counting the vacuum as the zeroth energy level),
which is to say $p(3) = 2$ since $\{3, 2 + 1 \}$ are the ways to write $3$.
The line $T = 2$ in the left panel of \autoref{fig:spectrum_ctm} confirms these results.

With a fixed boundary, the spectrum in the disordered phase doesn't change.
In the ordered phase however, the two-fold degeneracy due to symmetry is lifted,
so the degeneracy of the $n$th energy level becomes $p(n)$.
As a consequence, the spectrum decays much faster. See the right panel of \autoref{fig:spectrum_ctm}.

At or close to criticality, the expression in \autoref{eq:rho_exact_expression_off_critical} breaks down,
and the spectrum of $\hat{\rho}$ is smoothened out.
In general, below and at criticality, the spectrum decays slower for a free boundary.
This is to be expected, since $A$ preserves the symmetry when the boundary is free.
At $T = 0$, $A$ has two equally large non-zero eigenvalues, representing either all up or all down spins on the boundary
of the quadrant, while for a fixed boundary, $A$ has one non-zero eigenvalue:
it represents a completely polarized state.

\begin{figure}
  \includegraphics[]{spectrum_ctm.tikz}
  \caption{First part of the spectrum of $A$ after $n = 1000$ steps with a bond dimension of $m =
  250$.}\label{fig:spectrum_ctm}
\end{figure}

\subsection{Implications for finite-$m$ simulations}\label{sec:implications_for_finite_m_simulations}

When approximating the corner transfer matrix with a free boundary in the ordered phase,
it is crucial to retain all basis states corresponding to an energy level \cite{okunishi1999universal}.
Failure to do so will lead to a symmetry-broken state.

\todo[inline]{Make this plot somewhere?}

\section{Equivalence to variational approximation in the space of matrix product states.}

\todo[inline]{Talk about Baxter, Rommer and Ostlund, and more recent MPS algorithms. Maybe
in appendix?}
